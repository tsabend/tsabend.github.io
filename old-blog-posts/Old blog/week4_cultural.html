<DOCTYPE! html>
<html >
	<head>
		<link rel="stylesheet" type="text/css" href="stylesheet.css">
		<title>Phase 0 -- A Story of Pre-Work</title>

	</head>
<!--Title image-->
	<div id="titleimage">
		<img src="./imgs/phase0blogheader.jpg">
	</div>
<!--sidebar-->
	<div id="sidebar">
		<p style="text-decoration: underline">Recent Posts</p><br>
		<p><strong>Technical Blog</strong></p>
<a href="./week1_technical.html"><p>Week 1</p></a>
<a href="./week1_technical.html"><p>Week 2</p></a>


		<br>
		<a href="./week1_cultural.html"><p><strong>Cultural Blog</strong></p></a>
	</div>
<!--Navigation bar -->
	<div id="navbar">
		<p><a href="./about.html">About</a> <a href="./week2_technical.html">Technical</a> <a href="./week1_cultural.html">Cultural</a> <a href="./contact.html">Contact</a></p>
	<hr>
	</div>

<!--Content -->
	<div id="content">
		<h1 class="posttitle">Speech Recognition <br>or<br> Where is my Jetpack?</h1>
		<h5 class="articledate">9:42 AM -- 8/9/2014</p>
		<h5 class="articledate">Thomas Abend</h1>

		<p>Many cultural critics and experts within the tech industry like Peter Thiel have bemoaned the lack of truly radical advances in technology. Sure social media is nice, but it's hardly The Jetsons. Where's my hovercar?</p>
<p>One of the technologies that has most captivated the imagination of science fiction is the computer that you talk to. From HAL to C-3PO, the idea that computers will interact with us based on what we say is ingrained into our image of the future. Apple's SIRI and Google's "OK, Google" functionality are mimics of this, but anyone who's used them knows that they really more like gimmicks. Despite the state of current technology, the upshot is real. Imagine traveling with an electronic translator or shouting at your house to turn up the heat from the relative comfort of your bed on a cold winter's day. Or just imagine that the speech recognition software at the customer support hotline doesn't ask you "Did you say: yes?" a million times (a request to which you can only helplessly reply "yes"). Will speech recognition technology ever be good enough to fulfill our visions of a future filled with robots?</p>
<p>To fully understand the depth behind the issues with SR (speech recognition) you first need to understand how the current solutions work. First a human speaks which gets picked up by an analog-digital converter (ADC), basically a mic, which samples the audio signal so it can be analyzed. Typically the audio will be compressed to a more uniform volume and then analysis is usually done by way of a fast-Fourier transform (FFT), which takes little snapshots of the audio signal every 1/100th of a second. FFTs can be used to match the audio signal with a library of existing word sounds usually centered around things like phonemes and plosives, the little sounds that we use to make up work.</p>
<p>Wow that sounds like magic, huh? Well the truth is it doesn't work very well. Because pronunciation and the conditions of the audio sample (think background noises) vary greatly, the best the program can really do is generate a probability. The statistical modeler used by most SRs today is called the Hidden Markov Model. This basically says how likely it is that a given phoneme is being spoken but it has to figure out where each phoneme started and ended, deal with the fact that we pronounce letters differently in different contexts, and account for background noise. I don't know if I've done enough to stress how incredibly difficult it is to be accurate using this method up to this point but let's just say super freaking difficult and requiring quite a bit of CPU strength.</p>
<p>At this point, there are two solutions to improving your SRs output and many programs might take a bit of each. One is to limit the available vocabulary. If you limit the vocabulary you are looking for to just two words, chances are that you can differentiate between the two with a high degree of accuracy. Certainly higher than when you're just accepting any sound. More generally the tactic of limiting vocabulary sizes is called called Context Free Grammar. Using vocabulary banks can vastly improve outcomes by looking at statistical likelihood and with machine learning you can create an ever improving database of a words probability of being used.</p>
<p>The other option is to have a system that you train to get better at recognizing your voice. By calibrating the system to your voice, you make it easier to match audio input to phonemes and improve the results of your SR.</p>
<p>To sum up, here are some of the difficulties an SR faces:<ul><li>There are a ton of words (the average human's vocabulary is over 100,000 words)</li><li>People speak them differently</li><li>People don't always speak fluidly</li><li>Background Noise</li><li>Some letters are hard to distinguish</li></ul></p>
	<p>Just look back at the previous 5 paragraphs and look how many fancy acronyms there were. This stuff is really hard. The fact that we're able to take our speech break it into 1/100ths of a part per second and reconstruct that into sentences is borderline magic. The reason so many people are frustrated is that it seems almost good enough to work and that it's been around for a while. We've gotten close enough to a working SR that people ridicule SIRI when she doesn't know if you want to call "Mom" or "Bob" when you scream at her in a crowded nightclub. The idea that the technology is within reach but doesn't seem to be improving (SRs have been around since the early 80's) makes it all the more painful when it doesn't work.</p><p>Although the "when" remains uncertain, quality SR still seems like an inevitability. A main reason for the apparent sluggishness in progress is that researchers are constantly increasing difficulty of the tasks that SRs are being asked to do by expanding their vocabularies. One recent trend that seems to be accelerating the progress of SR is the growing use of machine learning methods to analyze and catalog existing speech data. That combined with the increasing power of computers is moving SR closer to its full potential.</p>
<p>Sources<ul><li><a href="http://electronics.howstuffworks.com/gadgets/high-tech-gadgets/speech-recognition1.htm">http://electronics.howstuffworks.com/gadgets/high-tech-gadgets/speech-recognition1.htm</a></li><li><a href="http://www.newyorker.com/magazine/2011/11/28/no-death-no-taxes">http://www.newyorker.com/magazine/2011/11/28/no-death-no-taxes</a></li><li><a href="http://www.cnn.com/2013/08/20/opinion/wheeler-voice-recognition/">http://www.cnn.com/2013/08/20/opinion/wheeler-voice-recognition/</a></li><li><a href="http://project.uet.itgo.com/speech.htm">http://project.uet.itgo.com/speech.htm</a></li><li><a href="http://en.wikipedia.org/wiki/Speech_recognition">http://en.wikipedia.org/wiki/Speech_recognition</a></li></ul></p>

	</div>
	<hr>

<!--footer-->
	<div id="footer">
		<p>Copyright Thomas Abend 2014</p>
	</div>
</html>



